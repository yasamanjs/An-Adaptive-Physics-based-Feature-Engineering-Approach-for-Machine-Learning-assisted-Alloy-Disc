{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "g3tvhbRBXDVe"
   },
   "outputs": [],
   "source": [
    "############################## 1- Read Data ####################################\n",
    "\n",
    "#### Pandas is used for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "### load data\n",
    "# features = pd.read_excel('Alldata236_mixed.xlsx', sheet_name='4tempercolumn')\n",
    "# features = pd.read_excel('Alldata236_mixed.xlsx', sheet_name='2tempercolumn')\n",
    "# features = pd.read_excel('Alldata236_mixed.xlsx', sheet_name='4tempercolumn-missing')\n",
    "# features = pd.read_excel('Alldata236_AE.xlsx', sheet_name='4tempercolumn-O8')\n",
    "# features = pd.read_excel('Alldata236_AE.xlsx', sheet_name='4tempercolumn-O13')\n",
    "# features = pd.read_excel('Alldata236_ordinal.xlsx')\n",
    "features = pd.read_excel('Alldata236.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alloy name</th>\n",
       "      <th>temper_type</th>\n",
       "      <th>temper</th>\n",
       "      <th>Si (%)</th>\n",
       "      <th>Fe (%)</th>\n",
       "      <th>Cu (%)</th>\n",
       "      <th>Mn (%)</th>\n",
       "      <th>Mg (%)</th>\n",
       "      <th>Cr (%)</th>\n",
       "      <th>Ni (%)</th>\n",
       "      <th>...</th>\n",
       "      <th>Endurance</th>\n",
       "      <th>RGC</th>\n",
       "      <th>RSCC</th>\n",
       "      <th>Extr</th>\n",
       "      <th>CW</th>\n",
       "      <th>Mach</th>\n",
       "      <th>RSW</th>\n",
       "      <th>Braz</th>\n",
       "      <th>GW</th>\n",
       "      <th>AW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5182.0</td>\n",
       "      <td>H111</td>\n",
       "      <td>H111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.35</td>\n",
       "      <td>4.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>125.0</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>Fair</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>Borderline</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Borderline</td>\n",
       "      <td>Fair</td>\n",
       "      <td>Excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5454.0</td>\n",
       "      <td>H111</td>\n",
       "      <td>H111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.80</td>\n",
       "      <td>2.70</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>130.0</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>Borderline</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Borderline</td>\n",
       "      <td>Fair</td>\n",
       "      <td>Excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5059.0</td>\n",
       "      <td>H111</td>\n",
       "      <td>H111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.90</td>\n",
       "      <td>5.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>165.0</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>Fair</td>\n",
       "      <td>Borderline</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Borderline</td>\n",
       "      <td>Fair</td>\n",
       "      <td>Excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6101.0</td>\n",
       "      <td>H111</td>\n",
       "      <td>H111</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Fair</td>\n",
       "      <td>Fair</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5254.0</td>\n",
       "      <td>H112</td>\n",
       "      <td>H112</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>115.0</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>Fair</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Borderline</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>2519.0</td>\n",
       "      <td>T87</td>\n",
       "      <td>T87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.80</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>115.0</td>\n",
       "      <td>Borderline</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>Borderline</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>Borderline</td>\n",
       "      <td>Borderline</td>\n",
       "      <td>Fair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>2219.0</td>\n",
       "      <td>T87</td>\n",
       "      <td>T87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.30</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>107.5</td>\n",
       "      <td>Borderline</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>Borderline</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Borderline</td>\n",
       "      <td>Borderline</td>\n",
       "      <td>Fair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>6262.0</td>\n",
       "      <td>T9</td>\n",
       "      <td>T9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Fair</td>\n",
       "      <td>Fair</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>238 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     alloy name temper_type temper  Si (%)  Fe (%)  Cu (%)  Mn (%)  Mg (%)  \\\n",
       "0        5182.0        H111   H111     0.0     0.0    0.00    0.35    4.50   \n",
       "1        5454.0        H111   H111     0.0     0.0    0.00    0.80    2.70   \n",
       "2        5059.0        H111   H111     0.0     0.0    0.00    0.90    5.50   \n",
       "3        6101.0        H111   H111     0.5     0.0    0.00    0.00    0.60   \n",
       "4        5254.0        H112   H112     0.0     0.0    0.00    0.00    3.50   \n",
       "..          ...         ...    ...     ...     ...     ...     ...     ...   \n",
       "233      2519.0         T87    T87     0.0     0.0    5.80    0.30    0.22   \n",
       "234      2219.0         T87    T87     0.0     0.0    6.30    0.30    0.00   \n",
       "235      6262.0          T9     T9     0.6     0.0    0.28    0.00    1.00   \n",
       "236         NaN         NaN    NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "237         NaN         NaN    NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "\n",
       "     Cr (%)  Ni (%)  ...  Endurance         RGC       RSCC       Extr  \\\n",
       "0      0.00     0.0  ...      125.0   Excellent  Very Good       Fair   \n",
       "1      0.12     0.0  ...      130.0   Excellent  Excellent  Very Good   \n",
       "2      0.00     0.0  ...      165.0   Excellent  Very Good  Very Good   \n",
       "3      0.00     0.0  ...       40.0   Excellent  Excellent  Excellent   \n",
       "4      0.25     0.0  ...      115.0   Excellent  Excellent  Very Good   \n",
       "..      ...     ...  ...        ...         ...        ...        ...   \n",
       "233    0.00     0.0  ...      115.0  Borderline  Very Good  Very Good   \n",
       "234    0.00     0.0  ...      107.5  Borderline  Very Good  Very Good   \n",
       "235    0.09     0.0  ...       90.0   Very Good  Excellent  Excellent   \n",
       "236     NaN     NaN  ...        NaN         NaN        NaN        NaN   \n",
       "237     NaN     NaN  ...        NaN         NaN        NaN        NaN   \n",
       "\n",
       "             CW        Mach        RSW        Braz          GW         AW  \n",
       "0     Very Good  Borderline  Excellent  Borderline        Fair  Excellent  \n",
       "1     Very Good  Borderline  Excellent  Borderline        Fair  Excellent  \n",
       "2          Fair  Borderline  Excellent  Borderline        Fair  Excellent  \n",
       "3          Fair        Fair  Excellent   Excellent   Excellent  Excellent  \n",
       "4     Very Good        Fair  Excellent  Borderline   Excellent  Excellent  \n",
       "..          ...         ...        ...         ...         ...        ...  \n",
       "233  Borderline   Very Good  Very Good  Borderline  Borderline       Fair  \n",
       "234  Borderline   Very Good  Excellent  Borderline  Borderline       Fair  \n",
       "235        Fair        Fair  Excellent   Excellent   Excellent  Excellent  \n",
       "236         NaN         NaN        NaN         NaN         NaN        NaN  \n",
       "237         NaN         NaN        NaN         NaN         NaN        NaN  \n",
       "\n",
       "[238 rows x 27 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features['temper'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "pLgLs_tSXZye"
   },
   "outputs": [],
   "source": [
    "############ define mechanical properties labels\n",
    "\n",
    "label1 = np.array(features['UTS'])\n",
    "label2 = np.array(features['TYS'])\n",
    "label3 = np.array(features['El'])\n",
    "label4 = np.array(features['BHN'])\n",
    "label5 = np.array(features['Shear'])\n",
    "label6 = np.array(features['Endu'])\n",
    "\n",
    "#### removing properties, labels, and unnecessary columns from the input features\n",
    "features= features.drop('UTS', axis = 1)\n",
    "features= features.drop('TYS', axis = 1)\n",
    "features= features.drop('El', axis = 1)\n",
    "features= features.drop('BHN', axis = 1)\n",
    "features= features.drop('Shear', axis = 1)\n",
    "features= features.drop('Endu', axis = 1)\n",
    "\n",
    "features= features.drop('RGC', axis = 1)\n",
    "features= features.drop('RSCC', axis = 1)\n",
    "features= features.drop('CW', axis = 1)\n",
    "features= features.drop('Mach', axis = 1)\n",
    "features= features.drop('Braz', axis = 1)\n",
    "features= features.drop('GW', axis = 1)\n",
    "features= features.drop('AW', axis = 1)\n",
    "features= features.drop('RSW', axis = 1)\n",
    "features= features.drop('Extr', axis = 1)\n",
    "\n",
    "features= features.drop('alloy name', axis = 1)\n",
    "\n",
    "features= features.drop('temper_type', axis = 1)\n",
    "\n",
    "# features= features.drop('Type', axis = 1)\n",
    "# features= features.drop('digit1', axis = 1)\n",
    "# features= features.drop('digit2', axis = 1)\n",
    "# features= features.drop('digit3', axis = 1)\n",
    "\n",
    "\n",
    "n_samples, n_features = features.shape\n",
    "# One-hot encode categorical features (to encode)\n",
    "features = pd.get_dummies(features)\n",
    "\n",
    "# Saving feature names for later use\n",
    "feature_list = list(features.columns)\n",
    "features = np.array(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(236, 15)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "SfLTrpC-XVHV"
   },
   "outputs": [],
   "source": [
    "############################# evaluate function #############################\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def evaluate(true_labels, pred_labels):\n",
    "    errors = abs(pred_labels - true_labels)\n",
    "    MAE = round(np.mean(errors), 2)\n",
    "    MAE2 = mean_absolute_error(true_labels, pred_labels)\n",
    "    mape = 100 * np.mean(errors / true_labels)\n",
    "    #R2, and adjusted R2\n",
    "    from sklearn.metrics import r2_score\n",
    "    r2 = r2_score(true_labels, pred_labels)\n",
    "\n",
    "    ## p is the total number of explanatory variables in the model\n",
    "    ## and n is the sample size.\n",
    "    p = n_features\n",
    "    n = n_samples\n",
    "    \n",
    "    r2_adjusted = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "    r2_adjusted = np.array(r2_adjusted)\n",
    "\n",
    "\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    RMSE = mean_squared_error(true_labels, pred_labels,squared=False)\n",
    "\n",
    "    #return accuracy, MAE, MAPE, r2_adjusted, r2_mean_5cv\n",
    "    return mape, MAE, RMSE, r2, r2_adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "JN_39E0NmK0L"
   },
   "outputs": [],
   "source": [
    "\n",
    "final_output_UTS = pd.DataFrame()\n",
    "final_output_TYS = pd.DataFrame()\n",
    "final_output_Elong = pd.DataFrame()\n",
    "final_output_BHN = pd.DataFrame()\n",
    "final_output_Shear = pd.DataFrame()\n",
    "final_output_Endurance = pd.DataFrame()\n",
    "final_output_Elastic = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##### hptuing SVM\n",
    "# from sklearn import svm\n",
    "\n",
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# grid = {'kernel': ('linear', 'rbf','poly'),\n",
    "#         'C':[1,10, 100, 200, 300, 350, 400, 450,500,600, 'scale', 'auto'],\n",
    "#         'gamma': [1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 0.1, 0.2],\n",
    "#         'epsilon':[0.001, 0.005, 0.01,0.05, 0.1, 0.2]}\n",
    "# # grid = {'C': [1], 'epsilon': [0.1]}\n",
    "\n",
    "# model = svm.SVR()\n",
    "\n",
    "\n",
    "\n",
    "# grid_search1 = RandomizedSearchCV(estimator = model, param_distributions = grid,\n",
    "#                                    refit = True,\n",
    "#                                    n_iter = 100, cv = 5, verbose=2,\n",
    "#                                    random_state=100, scoring='r2', n_jobs = -1)\n",
    "\n",
    "# grid_search2 = RandomizedSearchCV(estimator = model, param_distributions = grid,\n",
    "#                                    refit = True,\n",
    "#                                    n_iter = 100, cv = 5, verbose=2,\n",
    "#                                    random_state=100, scoring='r2', n_jobs = -1)\n",
    "\n",
    "# grid_search3 =RandomizedSearchCV(estimator = model, param_distributions = grid,\n",
    "#                                    refit = True,\n",
    "#                                    n_iter = 100, cv = 5, verbose=2,\n",
    "#                                    random_state=100, scoring='r2', n_jobs = -1)\n",
    "\n",
    "# grid_search4 = RandomizedSearchCV(estimator = model, param_distributions = grid,\n",
    "#                                    refit = True,\n",
    "#                                    n_iter = 100, cv = 5, verbose=2,\n",
    "#                                    random_state=100, scoring='r2', n_jobs = -1)\n",
    "\n",
    "# grid_search5 = RandomizedSearchCV(estimator = model, param_distributions = grid,\n",
    "#                                    refit = True,\n",
    "#                                    n_iter = 100, cv = 5, verbose=2,\n",
    "#                                    random_state=100, scoring='r2', n_jobs = -1)\n",
    "\n",
    "# grid_search6 = RandomizedSearchCV(estimator = model, param_distributions = grid,\n",
    "#                                    refit = True,\n",
    "#                                    n_iter = 100, cv = 5, verbose=2,\n",
    "#                                    random_state=100, scoring='r2', n_jobs = -1)\n",
    "\n",
    "\n",
    "\n",
    "# # Fit the grid search to the data\n",
    "# grid_search1.fit(train_features1, train_labels1)\n",
    "# grid_search2.fit(train_features2, train_labels2)\n",
    "# grid_search3.fit(train_features3, train_labels3)\n",
    "# grid_search4.fit(train_features4, train_labels4)\n",
    "# grid_search5.fit(train_features5, train_labels5)\n",
    "# grid_search6.fit(train_features6, train_labels6)\n",
    "\n",
    "# ######### Grid Search #####################\n",
    "# best_grid1 = grid_search1.best_estimator_\n",
    "# best_grid2 = grid_search2.best_estimator_\n",
    "# best_grid3 = grid_search3.best_estimator_\n",
    "# best_grid4 = grid_search4.best_estimator_\n",
    "# best_grid5 = grid_search5.best_estimator_\n",
    "# best_grid6 = grid_search6.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "9oC1dR8jXgzG",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "1\n",
      "1\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "2\n",
      "2\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "3\n",
      "3\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "4\n",
      "4\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "5\n",
      "5\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "6\n",
      "6\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "7\n",
      "7\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "8\n",
      "8\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "9\n",
      "9\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "10\n",
      "10\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "11\n",
      "11\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "12\n",
      "12\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "13\n",
      "13\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "14\n",
      "14\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "15\n",
      "15\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "16\n",
      "16\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "17\n",
      "17\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "18\n",
      "18\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "19\n",
      "19\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "20\n",
      "20\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "21\n",
      "21\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "22\n",
      "22\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "23\n",
      "23\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "24\n",
      "24\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "25\n",
      "25\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "26\n",
      "26\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "27\n",
      "27\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "28\n",
      "28\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "29\n",
      "29\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "30\n",
      "30\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "31\n",
      "31\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "32\n",
      "32\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "33\n",
      "33\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "34\n",
      "34\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "35\n",
      "35\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "36\n",
      "36\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "37\n",
      "37\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "38\n",
      "38\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "39\n",
      "39\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "40\n",
      "40\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "41\n",
      "41\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "42\n",
      "42\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "43\n",
      "43\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "44\n",
      "44\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "45\n",
      "45\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "46\n",
      "46\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "47\n",
      "47\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "48\n",
      "48\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "49\n",
      "49\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "50\n",
      "50\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "51\n",
      "51\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "52\n",
      "52\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "53\n",
      "53\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "54\n",
      "54\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "55\n",
      "55\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "56\n",
      "56\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "57\n",
      "57\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "58\n",
      "58\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "59\n",
      "59\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "60\n",
      "60\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "61\n",
      "61\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "62\n",
      "62\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "63\n",
      "63\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "64\n",
      "64\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "65\n",
      "65\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "66\n",
      "66\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "67\n",
      "67\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "68\n",
      "68\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "69\n",
      "69\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "70\n",
      "70\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "71\n",
      "71\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "72\n",
      "72\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "73\n",
      "73\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "74\n",
      "74\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "75\n",
      "75\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "76\n",
      "76\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "77\n",
      "77\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "78\n",
      "78\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "79\n",
      "79\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "80\n",
      "80\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "81\n",
      "81\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "82\n",
      "82\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "83\n",
      "83\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "84\n",
      "84\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "85\n",
      "85\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "86\n",
      "86\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "87\n",
      "87\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "88\n",
      "88\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "89\n",
      "89\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "90\n",
      "90\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "91\n",
      "91\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "92\n",
      "92\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "93\n",
      "93\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "94\n",
      "94\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "95\n",
      "95\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "96\n",
      "96\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "97\n",
      "97\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "98\n",
      "98\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n",
      "99\n",
      "99\n",
      "###################################################################\n",
      "evaluatoin of the RF model on testing dataset\n"
     ]
    }
   ],
   "source": [
    "  ################### the loop for trying 100 seeds ###########################\n",
    "  ##### at each iteration, a random seed is defined, \n",
    "  ##### test/train is split for that seed, models are devloped, \n",
    "  ##### trained and evaluated.\n",
    "from sklearn.model_selection import train_test_split\n",
    "i = 0\n",
    "\n",
    "for j in range(100): #trying range of 0 to 99 for seeds to do the split\n",
    "# for j in A:\n",
    "    Seed = j\n",
    "    print(j)\n",
    "    \n",
    "    test_ratio = 0.2\n",
    "\n",
    "    train_features1, test_features1, train_labels1, test_labels1 = train_test_split(features, label1,\n",
    "                                                                                test_size = test_ratio,\n",
    "                                                                                random_state = Seed)\n",
    "\n",
    "\n",
    "    train_features2, test_features2, train_labels2, test_labels2 = train_test_split(features, label2,\n",
    "                                                                                test_size = test_ratio,\n",
    "                                                                                random_state = Seed)\n",
    "\n",
    "\n",
    "    train_features3, test_features3, train_labels3, test_labels3 = train_test_split(features, label3,\n",
    "                                                                                test_size = test_ratio,\n",
    "                                                                                random_state = Seed)\n",
    "\n",
    "\n",
    "    train_features4, test_features4, train_labels4, test_labels4 = train_test_split(features, label4,\n",
    "                                                                                test_size = test_ratio,\n",
    "                                                                                random_state = Seed)\n",
    "\n",
    "\n",
    "    train_features5, test_features5, train_labels5, test_labels5 = train_test_split(features, label5,\n",
    "                                                                                test_size =test_ratio,\n",
    "                                                                                random_state = Seed)\n",
    "\n",
    "\n",
    "    train_features6, test_features6, train_labels6, test_labels6 = train_test_split(features, label6,\n",
    "                                                                                test_size = test_ratio,\n",
    "                                                                                random_state = Seed)\n",
    "\n",
    "    print(i)\n",
    "    ################## build Model ######################################\n",
    "    ################################################################################\n",
    "    SEED = 100\n",
    "    # ######################## Random Forest ###################################\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    ## RF default\n",
    "    Model1 = RandomForestRegressor(random_state=SEED)\n",
    "    Model2 = RandomForestRegressor(random_state=SEED)\n",
    "    Model3 = RandomForestRegressor(random_state=SEED)\n",
    "    Model4 = RandomForestRegressor(random_state=SEED)\n",
    "    Model5 = RandomForestRegressor(random_state=SEED)\n",
    "    Model6 = RandomForestRegressor(random_state=SEED)\n",
    "\n",
    "    ##### SVM\n",
    "#     from sklearn import svm\n",
    "#     Model1 = svm.SVR(kernel='rbf', gamma=0.2, C=500, epsilon=0.01)\n",
    "#     Model2 = svm.SVR(kernel='rbf', gamma=0.2, C=500, epsilon=0.01)\n",
    "#     Model3 = svm.SVR(kernel='rbf', gamma=0.1, C=300, epsilon=0.05)\n",
    "#     Model4 = svm.SVR(kernel='rbf', gamma=0.1, C=300, epsilon=0.05)\n",
    "#     Model5 = svm.SVR(kernel='rbf', gamma=0.1, C=350, epsilon=0.001)\n",
    "#     Model6 = svm.SVR(kernel='rbf', gamma=0.01, C=500, epsilon=0.1)\n",
    "\n",
    "    ################# Evaluation ##################\n",
    "\n",
    "    Model1.fit(train_features1,train_labels1)\n",
    "    Model2.fit(train_features2,train_labels2)\n",
    "    Model3.fit(train_features3,train_labels3)\n",
    "    Model4.fit(train_features4,train_labels4)\n",
    "    Model5.fit(train_features5,train_labels5)\n",
    "    Model6.fit(train_features6,train_labels6)\n",
    "\n",
    "    print('###################################################################')\n",
    "    print('evaluatoin of the RF model on testing dataset')\n",
    "\n",
    "    predictions1 = Model1.predict(test_features1)\n",
    "    predictions2 = Model2.predict(test_features2)\n",
    "    predictions3 = Model3.predict(test_features3)\n",
    "    predictions4 = Model4.predict(test_features4)\n",
    "    predictions5 = Model5.predict(test_features5)\n",
    "    predictions6 = Model6.predict(test_features6)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    model_accuracy1, model_MAE1, model_RMSE1, model_r21, model_r2_adjusted1 = evaluate(test_labels1, predictions1)\n",
    "    model_accuracy2, model_MAE2, model_RMSE2, model_r22, model_r2_adjusted2 = evaluate(test_labels2, predictions2)\n",
    "    model_accuracy3, model_MAE3, model_RMSE3, model_r23, model_r2_adjusted3 = evaluate(test_labels3, predictions3)\n",
    "    model_accuracy4, model_MAE4, model_RMSE4, model_r24, model_r2_adjusted4 = evaluate(test_labels4, predictions4)\n",
    "    model_accuracy5, model_MAE5, model_RMSE5, model_r25, model_r2_adjusted5 = evaluate(test_labels5, predictions5)\n",
    "    model_accuracy6, model_MAE6, model_RMSE6, model_r26, model_r2_adjusted6 = evaluate(test_labels6, predictions6)\n",
    "\n",
    "\n",
    "\n",
    "    final_output_UTS.loc[:,i] = [model_accuracy1, model_MAE1, model_RMSE1, model_r21, model_r2_adjusted1]\n",
    "    final_output_TYS.loc[:,i] = [model_accuracy2, model_MAE2, model_RMSE2, model_r22, model_r2_adjusted2]\n",
    "    final_output_Elong.loc[:,i] = [model_accuracy3, model_MAE3, model_RMSE3, model_r23, model_r2_adjusted3]\n",
    "    final_output_BHN.loc[:,i] = [model_accuracy4, model_MAE4, model_RMSE4, model_r24, model_r2_adjusted4]\n",
    "    final_output_Shear.loc[:,i] = [model_accuracy5, model_MAE5, model_RMSE5, model_r25, model_r2_adjusted5]\n",
    "    final_output_Endurance.loc[:,i] = [model_accuracy6, model_MAE6, model_RMSE6, model_r26, model_r2_adjusted6]\n",
    "\n",
    "\n",
    "    i = i+1\n",
    "    i\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "iUK7P2dOYF4x"
   },
   "outputs": [],
   "source": [
    "\n",
    "### collecting evaluation metrices for all 100 seeds for each property\n",
    "\n",
    "final_output_UTS = pd.DataFrame(final_output_UTS)\n",
    "final_output_TYS = pd.DataFrame(final_output_TYS)\n",
    "final_output_Elong = pd.DataFrame(final_output_Elong)\n",
    "final_output_BHN = pd.DataFrame(final_output_BHN)\n",
    "final_output_Shear = pd.DataFrame(final_output_Shear)\n",
    "final_output_Endurance = pd.DataFrame(final_output_Endurance)\n",
    "\n",
    "final_output_UTS = final_output_UTS.T\n",
    "final_output_TYS = final_output_TYS.T\n",
    "final_output_Elong = final_output_Elong.T\n",
    "final_output_BHN = final_output_BHN.T\n",
    "final_output_Shear = final_output_Shear.T\n",
    "final_output_Endurance = final_output_Endurance.T\n",
    "\n",
    "\n",
    "# final_output_UTS.to_excel(r'final_output_UTS_OE.xlsx', index = True)\n",
    "\n",
    "# final_output_TYS.to_excel(r'final_output_TYS_OE.xlsx', index = True)\n",
    "\n",
    "# final_output_Elong.to_excel(r'final_output_Elong_OE.xlsx', index = True)\n",
    "\n",
    "# final_output_BHN.to_excel(r'final_output_BHN_OE.xlsx', index = True)\n",
    "\n",
    "# final_output_Shear.to_excel(r'final_output_Shear_OE.xlsx', index = True)\n",
    "\n",
    "# final_output_Endurance.to_excel(r'final_output_Endurance_OE.xlsx', index = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "SO4KEf1DUB6R"
   },
   "outputs": [],
   "source": [
    "###### mean and std of 100 evaluation metrices\n",
    "Final_results_mean = [final_output_UTS.mean(), final_output_TYS.mean(), final_output_Elong.mean(), final_output_BHN.mean(), final_output_Shear.mean(), final_output_Endurance.mean()]\n",
    "Final_results_std = [final_output_UTS.std(), final_output_TYS.std(), final_output_Elong.std(), final_output_BHN.std(), final_output_Shear.std(), final_output_Endurance.std()]\n",
    "\n",
    "Final_results_mean = pd.DataFrame(Final_results_mean)\n",
    "Final_results_std = pd.DataFrame(Final_results_std)\n",
    "\n",
    "# Final_results_mean.to_excel(r'final_results_mean_mixed.xlsx', index = True)\n",
    "# Final_results_std.to_excel(r'final_results_std_mixed.xlsx', index = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.393967</td>\n",
       "      <td>29.9502</td>\n",
       "      <td>40.757999</td>\n",
       "      <td>0.914110</td>\n",
       "      <td>0.909080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.550971</td>\n",
       "      <td>31.1376</td>\n",
       "      <td>44.621246</td>\n",
       "      <td>0.897749</td>\n",
       "      <td>0.891761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.473451</td>\n",
       "      <td>2.2856</td>\n",
       "      <td>3.266457</td>\n",
       "      <td>0.745848</td>\n",
       "      <td>0.730965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.974702</td>\n",
       "      <td>8.8423</td>\n",
       "      <td>12.223986</td>\n",
       "      <td>0.896372</td>\n",
       "      <td>0.890304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.529389</td>\n",
       "      <td>18.1878</td>\n",
       "      <td>25.593095</td>\n",
       "      <td>0.899945</td>\n",
       "      <td>0.894086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16.189018</td>\n",
       "      <td>11.8990</td>\n",
       "      <td>17.652381</td>\n",
       "      <td>0.785064</td>\n",
       "      <td>0.772478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0        1          2         3         4\n",
       "0  10.393967  29.9502  40.757999  0.914110  0.909080\n",
       "1  14.550971  31.1376  44.621246  0.897749  0.891761\n",
       "2  18.473451   2.2856   3.266457  0.745848  0.730965\n",
       "3  10.974702   8.8423  12.223986  0.896372  0.890304\n",
       "4  11.529389  18.1878  25.593095  0.899945  0.894086\n",
       "5  16.189018  11.8990  17.652381  0.785064  0.772478"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_results_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPZJ8nYLewS0EftCsqxG+Qg",
   "collapsed_sections": [],
   "name": "100seeds_mechanical.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
